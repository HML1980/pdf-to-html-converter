"""
OCRæ–‡å­—è­˜åˆ¥è™•ç†æ¨¡çµ„ - éšæ®µ3
ä½¿ç”¨Tesseracté€²è¡Œä¸­æ–‡ç¹é«”æ–‡å­—è­˜åˆ¥ï¼Œæå–åº§æ¨™ä½ç½®è³‡è¨Š
"""

import os
import sys
import json
import logging
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Any
import time
from datetime import datetime
import cv2
import numpy as np

try:
    import pytesseract
    from PIL import Image, ImageEnhance, ImageFilter
    import pandas as pd
except ImportError:
    print("âš ï¸  ç¼ºå°‘å¿…è¦å¥—ä»¶ï¼Œè«‹å®‰è£ï¼š")
    print("pip install pytesseract opencv-python pandas")
    print("å¦å¤–éœ€è¦å®‰è£ Tesseract OCRï¼š")
    print("Windows: å¾ https://github.com/UB-Mannheim/tesseract/wiki ä¸‹è¼‰")
    print("Ubuntu: sudo apt install tesseract-ocr tesseract-ocr-chi-tra")
    print("macOS: brew install tesseract tesseract-lang")


class OCRProcessor:
    """OCRæ–‡å­—è­˜åˆ¥è™•ç†ä¸»é¡åˆ¥"""
    
    def __init__(self, base_path: str = "D:/pdf-to-html-converter"):
        """
        åˆå§‹åŒ–OCRè™•ç†å™¨
        
        Args:
            base_path: å°ˆæ¡ˆæ ¹ç›®éŒ„è·¯å¾‘
        """
        self.base_path = Path(base_path)
        self.output_path = self.base_path / "output"
        self.images_path = self.output_path / "images"
        self.text_path = self.output_path / "text"
        self.logs_path = self.base_path / "logs"
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        self.text_path.mkdir(parents=True, exist_ok=True)
        self.logs_path.mkdir(parents=True, exist_ok=True)
        
        # è¨­ç½®æ—¥èªŒ
        self._setup_logging()
        
        # OCRè¨­å®š
        self.tesseract_config = {
            'lang': 'chi_tra+eng',  # ä¸­æ–‡ç¹é«” + è‹±æ–‡
            'config': '--psm 6 --oem 3',  # é é¢åˆ†æ®µæ¨¡å¼ + OCRå¼•æ“æ¨¡å¼
            'output_type': 'dict'  # è¼¸å‡ºå­—å…¸æ ¼å¼
        }
        
        # åœ–ç‰‡å‰è™•ç†åƒæ•¸
        self.preprocessing = {
            'resize_factor': 2.0,  # æ”¾å¤§å€æ•¸
            'contrast_enhance': 1.2,  # å°æ¯”åº¦å¢å¼·
            'sharpness_enhance': 1.1,  # éŠ³åˆ©åº¦å¢å¼·
            'noise_reduction': True,  # é™å™ª
            'binarization': True  # äºŒå€¼åŒ–
        }
        
        self.logger.info("OCRè™•ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        
    def _setup_logging(self):
        """è¨­ç½®æ—¥èªŒç³»çµ±"""
        log_filename = f"ocr_processor_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        log_filepath = self.logs_path / log_filename
        
        # å»ºç«‹logger
        self.logger = logging.getLogger('OCRProcessor')
        self.logger.setLevel(logging.INFO)
        
        # é¿å…é‡è¤‡handler
        if not self.logger.handlers:
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            
            # æª”æ¡ˆhandler
            file_handler = logging.FileHandler(log_filepath, encoding='utf-8')
            file_handler.setFormatter(formatter)
            self.logger.addHandler(file_handler)
            
            # çµ‚ç«¯æ©Ÿhandler
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(formatter)
            self.logger.addHandler(console_handler)
    
    def check_tesseract_installation(self) -> Tuple[bool, str]:
        """
        æª¢æŸ¥Tesseractå®‰è£ç‹€æ…‹
        
        Returns:
            (æ˜¯å¦å®‰è£, è¨Šæ¯)
        """
        try:
            # æª¢æŸ¥Tesseractå¯åŸ·è¡Œæª”
            version = pytesseract.get_tesseract_version()
            
            # æª¢æŸ¥èªè¨€åŒ…
            languages = pytesseract.get_languages()
            
            has_chi_tra = 'chi_tra' in languages
            has_eng = 'eng' in languages
            
            if has_chi_tra and has_eng:
                msg = f"âœ… Tesseract {version} å·²å®‰è£ï¼Œæ”¯æ´ä¸­æ–‡ç¹é«”å’Œè‹±æ–‡"
                self.logger.info(msg)
                return True, msg
            else:
                missing_langs = []
                if not has_chi_tra:
                    missing_langs.append('chi_tra')
                if not has_eng:
                    missing_langs.append('eng')
                    
                msg = f"âŒ ç¼ºå°‘èªè¨€åŒ…: {', '.join(missing_langs)}"
                self.logger.warning(msg)
                return False, msg
                
        except Exception as e:
            msg = f"âŒ Tesseractæœªå®‰è£æˆ–é…ç½®éŒ¯èª¤: {str(e)}"
            self.logger.error(msg)
            return False, msg
    
    def preprocess_image(self, image_path: str) -> Image.Image:
        """
        åœ–ç‰‡å‰è™•ç†ä»¥æé«˜OCRè­˜åˆ¥ç‡
        
        Args:
            image_path: åœ–ç‰‡æª”æ¡ˆè·¯å¾‘
            
        Returns:
            è™•ç†å¾Œçš„PIL Imageç‰©ä»¶
        """
        try:
            # è¼‰å…¥åœ–ç‰‡
            image = Image.open(image_path)
            
            # è½‰æ›ç‚ºRGBæ¨¡å¼
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # æ”¾å¤§åœ–ç‰‡æé«˜è§£æåº¦
            if self.preprocessing['resize_factor'] != 1.0:
                new_size = (
                    int(image.width * self.preprocessing['resize_factor']),
                    int(image.height * self.preprocessing['resize_factor'])
                )
                image = image.resize(new_size, Image.Resampling.LANCZOS)
            
            # å°æ¯”åº¦å¢å¼·
            if self.preprocessing['contrast_enhance'] != 1.0:
                enhancer = ImageEnhance.Contrast(image)
                image = enhancer.enhance(self.preprocessing['contrast_enhance'])
            
            # éŠ³åˆ©åº¦å¢å¼·
            if self.preprocessing['sharpness_enhance'] != 1.0:
                enhancer = ImageEnhance.Sharpness(image)
                image = enhancer.enhance(self.preprocessing['sharpness_enhance'])
            
            # é™å™ªè™•ç†
            if self.preprocessing['noise_reduction']:
                image = image.filter(ImageFilter.MedianFilter(size=3))
            
            # äºŒå€¼åŒ–è™•ç†
            if self.preprocessing['binarization']:
                # è½‰æ›ç‚ºOpenCVæ ¼å¼é€²è¡ŒäºŒå€¼åŒ–
                cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
                gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
                
                # è‡ªé©æ‡‰äºŒå€¼åŒ–
                binary = cv2.adaptiveThreshold(
                    gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                    cv2.THRESH_BINARY, 11, 2
                )
                
                # è½‰æ›å›PILæ ¼å¼
                image = Image.fromarray(binary)
                image = image.convert('RGB')
            
            return image
            
        except Exception as e:
            self.logger.error(f"åœ–ç‰‡å‰è™•ç†å¤±æ•—: {str(e)}")
            # è¿”å›åŸå§‹åœ–ç‰‡
            return Image.open(image_path)
    
    def extract_text_with_coordinates(self, image_path: str) -> Dict[str, Any]:
        """
        å¾åœ–ç‰‡ä¸­æå–æ–‡å­—å’Œåº§æ¨™è³‡è¨Š
        
        Args:
            image_path: åœ–ç‰‡æª”æ¡ˆè·¯å¾‘
            
        Returns:
            åŒ…å«æ–‡å­—å’Œåº§æ¨™è³‡è¨Šçš„å­—å…¸
        """
        try:
            self.logger.info(f"é–‹å§‹OCRè­˜åˆ¥: {Path(image_path).name}")
            
            # å‰è™•ç†åœ–ç‰‡
            processed_image = self.preprocess_image(image_path)
            
            # åŸ·è¡ŒOCRè­˜åˆ¥ - å–å¾—è©³ç´°è³‡æ–™
            ocr_data = pytesseract.image_to_data(
                processed_image,
                lang=self.tesseract_config['lang'],
                config=self.tesseract_config['config'],
                output_type=pytesseract.Output.DICT
            )
            
            # è§£æOCRçµæœ
            text_blocks = []
            page_text = ""
            
            for i in range(len(ocr_data['text'])):
                text = ocr_data['text'][i].strip()
                
                # éæ¿¾ç©ºæ–‡å­—å’Œä½ä¿¡å¿ƒåº¦æ–‡å­—
                confidence = int(ocr_data['conf'][i])
                if text and confidence > 30:  # ä¿¡å¿ƒåº¦é–¾å€¼
                    
                    # åº§æ¨™è³‡è¨Š
                    x = ocr_data['left'][i]
                    y = ocr_data['top'][i]
                    width = ocr_data['width'][i]
                    height = ocr_data['height'][i]
                    
                    # ä¼°ç®—å­—é«”å¤§å°ï¼ˆåŸºæ–¼é«˜åº¦ï¼‰
                    font_size = max(8, min(72, int(height * 0.75)))
                    
                    # æ–‡å­—å€å¡Šè³‡è¨Š
                    text_block = {
                        'text': text,
                        'x': x,
                        'y': y,
                        'width': width,
                        'height': height,
                        'confidence': confidence,
                        'font_size': font_size,
                        'level': ocr_data['level'][i],  # æ–‡å­—å±¤ç´šï¼ˆå­—å…ƒã€è©ã€è¡Œã€æ®µè½ç­‰ï¼‰
                        'block_num': ocr_data['block_num'][i],
                        'par_num': ocr_data['par_num'][i],
                        'line_num': ocr_data['line_num'][i],
                        'word_num': ocr_data['word_num'][i]
                    }
                    
                    text_blocks.append(text_block)
                    page_text += text + " "
            
            # çµ„ç¹”çµæœ
            result = {
                'image_path': str(image_path),
                'image_name': Path(image_path).name,
                'processing_time': datetime.now().isoformat(),
                'total_text_blocks': len(text_blocks),
                'full_text': page_text.strip(),
                'text_blocks': text_blocks,
                'image_dimensions': {
                    'original_width': processed_image.width,
                    'original_height': processed_image.height
                },
                'ocr_config': self.tesseract_config,
                'preprocessing_applied': self.preprocessing
            }
            
            self.logger.info(f"OCRå®Œæˆ: è­˜åˆ¥åˆ° {len(text_blocks)} å€‹æ–‡å­—å€å¡Š")
            return result
            
        except Exception as e:
            error_msg = f"OCRè­˜åˆ¥å¤±æ•—: {str(e)}"
            self.logger.error(error_msg)
            return {
                'image_path': str(image_path),
                'error': error_msg,
                'text_blocks': [],
                'full_text': ""
            }
    
    def detect_image_regions(self, image_path: str) -> List[Dict[str, Any]]:
        """
        æª¢æ¸¬åœ–ç‰‡ä¸­çš„éæ–‡å­—å€åŸŸï¼ˆåœ–è¡¨ã€åœ–ç‰‡ç­‰ï¼‰
        
        Args:
            image_path: åœ–ç‰‡æª”æ¡ˆè·¯å¾‘
            
        Returns:
            åœ–ç‰‡å€åŸŸåˆ—è¡¨
        """
        try:
            # è¼‰å…¥åœ–ç‰‡
            image = cv2.imread(image_path)
            if image is None:
                return []
                
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # ä½¿ç”¨é‚Šç·£æª¢æ¸¬æ‰¾å‡ºå¯èƒ½çš„åœ–ç‰‡å€åŸŸ
            edges = cv2.Canny(gray, 50, 150)
            
            # å°‹æ‰¾è¼ªå»“
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            image_regions = []
            
            for i, contour in enumerate(contours):
                # è¨ˆç®—è¼ªå»“é¢ç©
                area = cv2.contourArea(contour)
                
                # éæ¿¾å¤ªå°çš„å€åŸŸ
                if area < 1000:  # å¯èª¿æ•´é–¾å€¼
                    continue
                
                # å–å¾—é‚Šç•ŒçŸ©å½¢
                x, y, w, h = cv2.boundingRect(contour)
                
                # è¨ˆç®—é•·å¯¬æ¯”
                aspect_ratio = float(w) / h
                
                # ä¼°ç®—æ˜¯å¦ç‚ºåœ–ç‰‡å€åŸŸï¼ˆåŸºæ–¼é¢ç©å’Œé•·å¯¬æ¯”ï¼‰
                is_likely_image = area > 5000 and 0.2 < aspect_ratio < 5.0
                
                region = {
                    'region_id': f"img_region_{i:03d}",
                    'x': int(x),
                    'y': int(y),
                    'width': int(w),
                    'height': int(h),
                    'area': int(area),
                    'aspect_ratio': round(aspect_ratio, 2),
                    'is_likely_image': is_likely_image,
                    'confidence': min(100, int((area / 10000) * 100))  # ç°¡å–®çš„ä¿¡å¿ƒåº¦è¨ˆç®—
                }
                
                image_regions.append(region)
            
            # æŒ‰é¢ç©æ’åºï¼ˆå¤§åˆ°å°ï¼‰
            image_regions.sort(key=lambda x: x['area'], reverse=True)
            
            self.logger.info(f"æª¢æ¸¬åˆ° {len(image_regions)} å€‹å¯èƒ½çš„åœ–ç‰‡å€åŸŸ")
            return image_regions
            
        except Exception as e:
            self.logger.error(f"åœ–ç‰‡å€åŸŸæª¢æ¸¬å¤±æ•—: {str(e)}")
            return []
    
    def process_single_image(self, image_path: str) -> Dict[str, Any]:
        """
        è™•ç†å–®å¼µåœ–ç‰‡ï¼ˆæ–‡å­—è­˜åˆ¥ + åœ–ç‰‡å€åŸŸæª¢æ¸¬ï¼‰
        
        Args:
            image_path: åœ–ç‰‡æª”æ¡ˆè·¯å¾‘
            
        Returns:
            å®Œæ•´è™•ç†çµæœ
        """
        start_time = time.time()
        
        # æ–‡å­—è­˜åˆ¥
        text_result = self.extract_text_with_coordinates(image_path)
        
        # åœ–ç‰‡å€åŸŸæª¢æ¸¬
        image_regions = self.detect_image_regions(image_path)
        
        # çµ„åˆçµæœ
        result = {
            **text_result,
            'image_regions': image_regions,
            'processing_time_seconds': round(time.time() - start_time, 2)
        }
        
        return result
    
    def save_ocr_results(self, results: Dict[str, Any], output_path: str):
        """
        å„²å­˜OCRçµæœåˆ°JSONæª”æ¡ˆ
        
        Args:
            results: OCRè™•ç†çµæœ
            output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        try:
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"OCRçµæœå·²å„²å­˜: {output_path}")
            
        except Exception as e:
            self.logger.error(f"å„²å­˜OCRçµæœå¤±æ•—: {str(e)}")
    
    def process_pdf_images(self, pdf_name: str, progress_callback=None) -> Tuple[bool, str, List[str]]:
        """
        è™•ç†PDFå°æ‡‰çš„æ‰€æœ‰åœ–ç‰‡é é¢
        
        Args:
            pdf_name: PDFæª”æ¡ˆåç¨±ï¼ˆä¸å«å‰¯æª”åï¼‰
            progress_callback: é€²åº¦å›èª¿å‡½æ•¸
            
        Returns:
            (æˆåŠŸèˆ‡å¦, è¨Šæ¯, çµæœæª”æ¡ˆè·¯å¾‘åˆ—è¡¨)
        """
        try:
            # å°‹æ‰¾åœ–ç‰‡ç›®éŒ„
            images_dir = self.images_path / pdf_name
            if not images_dir.exists():
                return False, f"æ‰¾ä¸åˆ°åœ–ç‰‡ç›®éŒ„: {images_dir}", []
            
            # å°‹æ‰¾åœ–ç‰‡æª”æ¡ˆ
            image_files = list(images_dir.glob("*.png")) + list(images_dir.glob("*.jpg"))
            
            if not image_files:
                return False, f"ç›®éŒ„ä¸­æ²’æœ‰åœ–ç‰‡æª”æ¡ˆ: {images_dir}", []
            
            # æ’åºæª”æ¡ˆ
            image_files.sort()
            
            # å»ºç«‹è¼¸å‡ºç›®éŒ„
            text_output_dir = self.text_path / pdf_name
            text_output_dir.mkdir(exist_ok=True)
            
            print(f"ğŸ” é–‹å§‹OCRè™•ç†: {pdf_name}")
            print(f"ğŸ“ è™•ç† {len(image_files)} å€‹åœ–ç‰‡æª”æ¡ˆ")
            
            result_files = []
            total_files = len(image_files)
            
            for i, image_file in enumerate(image_files, 1):
                print(f"ğŸ”„ è™•ç†åœ–ç‰‡ {i}/{total_files}: {image_file.name}")
                
                # åŸ·è¡ŒOCRè™•ç†
                result = self.process_single_image(str(image_file))
                
                # å„²å­˜çµæœ
                result_filename = f"{image_file.stem}_ocr.json"
                result_path = text_output_dir / result_filename
                self.save_ocr_results(result, str(result_path))
                
                result_files.append(str(result_path))
                
                # é€²åº¦å›èª¿
                if progress_callback:
                    progress_callback(i, total_files, result_path)
                
                # é¡¯ç¤ºè™•ç†çµ±è¨ˆ
                if 'text_blocks' in result:
                    text_count = len(result['text_blocks'])
                    region_count = len(result.get('image_regions', []))
                    print(f"   âœ… è­˜åˆ¥æ–‡å­—å€å¡Š: {text_count}, åœ–ç‰‡å€åŸŸ: {region_count}")
            
            success_msg = f"âœ… OCRè™•ç†å®Œæˆï¼è™•ç†äº† {total_files} å€‹æª”æ¡ˆ"
            print(success_msg)
            
            return True, success_msg, result_files
            
        except Exception as e:
            error_msg = f"âŒ OCRæ‰¹æ¬¡è™•ç†å¤±æ•—: {str(e)}"
            self.logger.error(error_msg)
            return False, error_msg, []


def main():
    """æ¸¬è©¦ç”¨ä¸»å‡½æ•¸"""
    print("ğŸ” OCRæ–‡å­—è­˜åˆ¥è™•ç†å™¨æ¸¬è©¦")
    print("=" * 50)
    
    # åˆå§‹åŒ–è™•ç†å™¨
    processor = OCRProcessor()
    
    # æª¢æŸ¥Tesseractå®‰è£
    is_installed, message = processor.check_tesseract_installation()
    print(message)
    
    if not is_installed:
        print("\nâš ï¸  è«‹å…ˆå®‰è£Tesseract OCRå’Œä¸­æ–‡èªè¨€åŒ…")
        return
    
    # é¡¯ç¤ºè¨­å®šè³‡è¨Š
    print(f"ğŸ“ æ–‡å­—è¼¸å‡ºç›®éŒ„: {processor.text_path}")
    print(f"ğŸˆµ æ”¯æ´èªè¨€: {processor.tesseract_config['lang']}")
    print("=" * 50)
    
    print("âœ… OCRè™•ç†å™¨å·²æº–å‚™å°±ç·’ï¼")
    print("ğŸ’¡ ä½¿ç”¨æ–¹å¼ï¼š")
    print("   processor = OCRProcessor()")
    print("   success, msg, files = processor.process_pdf_images('your_pdf_name')")


if __name__ == "__main__":
    main()